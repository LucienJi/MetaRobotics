{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "from functorch import jacrev, vmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squashed gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LOG_NN_OUTPUT = -5\n",
    "MAX_LOG_NN_OUTPUT = 2\n",
    "SMALL_NUMBER = 1e-6\n",
    "class TorchSquashedGaussian:\n",
    "    \"\"\"A tanh-squashed Gaussian distribution defined by: mean, std, low, high.\n",
    "\n",
    "    The distribution will never return low or high exactly, but\n",
    "    `low`+SMALL_NUMBER or `high`-SMALL_NUMBER respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs,\n",
    "        model,\n",
    "        low: float = -1.0,\n",
    "        high: float = 1.0,\n",
    "    ):\n",
    "        \"\"\"Parameterizes the distribution via `inputs`.\n",
    "\n",
    "        Args:\n",
    "            low: The lowest possible sampling value\n",
    "                (excluding this value).\n",
    "            high: The highest possible sampling value\n",
    "                (excluding this value).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Split inputs into mean and log(std).\n",
    "        mean, log_std = torch.chunk(self.inputs, 2, dim=-1)\n",
    "        # Clip `scale` values (coming from NN) to reasonable values.\n",
    "        log_std = torch.clamp(log_std, MIN_LOG_NN_OUTPUT, MAX_LOG_NN_OUTPUT)\n",
    "        std = torch.exp(log_std)\n",
    "        self.dist = torch.distributions.normal.Normal(mean, std)\n",
    "        assert np.all(np.less(low, high))\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def deterministic_sample(self):\n",
    "        self.last_sample = self._squash(self.dist.mean)\n",
    "        return self.last_sample\n",
    "\n",
    "    def sample(self):\n",
    "        # Use the reparameterization version of `dist.sample` to allow for\n",
    "        # the results to be backprop'able e.g. in a loss term.\n",
    "\n",
    "        normal_sample = self.dist.rsample()\n",
    "        self.last_sample = self._squash(normal_sample)\n",
    "        return self.last_sample\n",
    "\n",
    "    def logp(self, x):\n",
    "        # Unsquash values (from [low,high] to ]-inf,inf[)\n",
    "        unsquashed_values = self._unsquash(x)\n",
    "        # Get log prob of unsquashed values from our Normal.\n",
    "        log_prob_gaussian = self.dist.log_prob(unsquashed_values)\n",
    "        # For safety reasons, clamp somehow, only then sum up.\n",
    "        log_prob_gaussian = torch.clamp(log_prob_gaussian, -100, 100)\n",
    "        log_prob_gaussian = torch.sum(log_prob_gaussian, dim=-1)\n",
    "        # Get log-prob for squashed Gaussian.\n",
    "        unsquashed_values_tanhd = torch.tanh(unsquashed_values)\n",
    "        log_prob = log_prob_gaussian - torch.sum(\n",
    "            torch.log(1 - unsquashed_values_tanhd**2 + SMALL_NUMBER), dim=-1\n",
    "        )\n",
    "        return log_prob\n",
    "\n",
    "    def sample_logp(self):\n",
    "        z = self.dist.rsample()\n",
    "        actions = self._squash(z)\n",
    "        return actions, torch.sum(\n",
    "            self.dist.log_prob(z) - torch.log(1 - actions * actions + SMALL_NUMBER),\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "    def entropy(self):\n",
    "        raise ValueError(\"Entropy not defined for SquashedGaussian!\")\n",
    "\n",
    "    def kl(self, other ):\n",
    "        raise ValueError(\"KL not defined for SquashedGaussian!\")\n",
    "\n",
    "    def _squash(self, raw_values):\n",
    "        # Returned values are within [low, high] (including `low` and `high`).\n",
    "        squashed = ((torch.tanh(raw_values) + 1.0) / 2.0) * (\n",
    "            self.high - self.low\n",
    "        ) + self.low\n",
    "        return torch.clamp(squashed, self.low, self.high)\n",
    "\n",
    "    def _unsquash(self, values):\n",
    "        normed_values = (values - self.low) / (self.high - self.low) * 2.0 - 1.0\n",
    "        # Stabilize input to atanh.\n",
    "        save_normed_values = torch.clamp(\n",
    "            normed_values, -1.0 + SMALL_NUMBER, 1.0 - SMALL_NUMBER\n",
    "        )\n",
    "        unsquashed = torch.atanh(save_normed_values)\n",
    "        return unsquashed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.array([120]))\n",
    "x_max = 100\n",
    "\n",
    "loss = torch.clip( x - x_max , min = 0, max = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,1) \n",
    ")\n",
    "x = torch.randn(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jijingtian/miniconda3/envs/terrain/lib/python3.8/site-packages/torch/_functorch/deprecated.py:80: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.jacrev is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.jacrev instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('jacrev')\n",
      "/home/jijingtian/miniconda3/envs/terrain/lib/python3.8/site-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "jacob = vmap(jacrev(net))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacob_norm = torch.norm(jacob,2,dim=(1,2)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacob_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
