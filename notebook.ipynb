{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "from functorch import jacrev, vmap\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv,ResGatedGraphConv,SAGEConv, GatedGraphConv\n",
    "import torch.nn as nn \n",
    "from OnlineAdaptation.modules.vq_torch.vq_quantize import VectorQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(act_name):\n",
    "    if act_name == \"elu\":\n",
    "        return nn.ELU()\n",
    "    elif act_name == \"selu\":\n",
    "        return nn.SELU()\n",
    "    elif act_name == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif act_name == \"crelu\":\n",
    "        return nn.ReLU()\n",
    "    elif act_name == \"lrelu\":\n",
    "        return nn.LeakyReLU()\n",
    "    elif act_name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    elif act_name == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    elif act_name == \"identity\":\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        print(\"invalid activation function!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_index = {\n",
    "    '0': [0,1,2,3,4,5,6,7,8,9,10,11,48,49,50,51],\n",
    "}\n",
    "\n",
    "hip_index = {\n",
    "    '1': [12,24,36,48],\n",
    "    '2': [15,27,39,49],\n",
    "    '3': [18,30,42,50],\n",
    "    '4': [21,33,45,51],\n",
    "}\n",
    "thigh_index = {\n",
    "    '5': [13,25,37,48],\n",
    "    '6': [16,28,40,49],\n",
    "    '7': [19,31,43,50],\n",
    "    '8': [22,34,46,51],\n",
    "}\n",
    "calf_index = {\n",
    "    '9': [14,26,38,48],\n",
    "    '10': [17,29,41,49],\n",
    "    '11': [20,32,44,50],\n",
    "    '12': [23,35,47,51],\n",
    "}\n",
    "\n",
    "edge_index = [\n",
    "    [0,1],[0,2],[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10],[0,11],[0,12],\n",
    "    [1,5],[5,9],\n",
    "    [2,6],[6,10],\n",
    "    [3,7],[7,11],\n",
    "    [4,8],[8,12],\n",
    "]\n",
    "\n",
    "def mlp(input_dim, out_dim, hidden_sizes, activations):\n",
    "    layers = []\n",
    "    prev_h = input_dim\n",
    "    for h in hidden_sizes:\n",
    "        layers.append(nn.Linear(prev_h, h))\n",
    "        layers.append(activations)\n",
    "        prev_h = h\n",
    "    layers.append(nn.Linear(prev_h, out_dim))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_obs,\n",
    "                 num_history,\n",
    "                 num_latent,\n",
    "                 activation = 'relu',):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.num_obs = num_obs\n",
    "        self.num_latent = num_latent\n",
    "        activation_fn = get_activation(activation)\n",
    "        # graph info\n",
    "        node_base = torch.tensor(list(body_index.values()),dtype=torch.long).squeeze()\n",
    "        node_hip = torch.stack([torch.tensor(list(hip_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_thigh = torch.stack([torch.tensor(list(thigh_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_calf = torch.stack([torch.tensor(list(calf_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "\n",
    "        self.node_base = nn.Parameter(node_base, requires_grad=False)\n",
    "        self.node_hip = nn.Parameter(node_hip, requires_grad=False)\n",
    "        self.node_thigh = nn.Parameter(node_thigh, requires_grad=False)\n",
    "        self.node_calf = nn.Parameter(node_calf, requires_grad=False) \n",
    "\n",
    "        self.edge = torch.as_tensor(edge_index, dtype=torch.long).contiguous().t()\n",
    "\n",
    "        # build feature extractor for base, hip, thigh and calf\n",
    "        base_input_size = num_history * len(list(body_index.values())[0])\n",
    "        hip_input_size = num_history * len(list(hip_index.values())[0])\n",
    "        thigh_input_size = num_history * len(list(thigh_index.values())[0])\n",
    "        calf_input_size = num_history * len(list(calf_index.values())[0])\n",
    "        self.base_net = mlp(base_input_size, 2 * num_latent, [128, 64], activation_fn)\n",
    "        self.hip_net = mlp(hip_input_size, 2 * num_latent, [128, 64], activation_fn)\n",
    "        self.thigh_net = mlp(thigh_input_size, 2 * num_latent, [128, 64], activation_fn)\n",
    "        self.calf_net = mlp(calf_input_size, 2* num_latent, [128, 64], activation_fn)\n",
    "\n",
    "        # build graph net \n",
    "        self.gn = ResGatedGraphConv(in_channels= 2* num_latent,out_channels=2* num_latent)\n",
    "        self.gn2 = ResGatedGraphConv(in_channels= 2* num_latent,out_channels= num_latent)\n",
    "        self.act = activation_fn\n",
    "    \n",
    "    def _history2node(self,obs_history):\n",
    "        # obs_history.shape = (bz, n_histroy, n_obs)\n",
    "        base = obs_history[:,:,self.node_base].unsqueeze(1) # (bz, n_history, n_base)\n",
    "        hip = obs_history[:,:,self.node_hip].permute(0,2,1,3) # (bz, n_history, 4, 4)\n",
    "        thigh = obs_history[:,:,self.node_thigh].permute(0,2,1,3)\n",
    "        calf = obs_history[:,:,self.node_calf].permute(0,2,1,3) \n",
    "        base = self.base_net(base.flatten(-2,-1))\n",
    "        hip = self.hip_net(hip.flatten(-2,-1))\n",
    "        thigh = self.thigh_net(thigh.flatten(-2,-1))\n",
    "        calf = self.calf_net(calf.flatten(-2,-1))\n",
    "        return torch.cat([base,hip,thigh,calf],dim=1) # (bz, n_node,num_latent)\n",
    "    \n",
    "    def forward(self,obs_history):\n",
    "        nodes = self._history2node(obs_history)\n",
    "        nodes = self.gn(nodes,self.edge)\n",
    "        nodes = self.act(nodes)\n",
    "        nodes = self.gn2(nodes,self.edge)\n",
    "        return nodes\n",
    "\n",
    "    \n",
    "class GraphActor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_obs,\n",
    "                 num_latent,\n",
    "                 num_actions,\n",
    "                 activation = 'elu',\n",
    "                 actor_hidden_dims = [512, 256, 128]):\n",
    "        super().__init__()\n",
    "        self.num_latent = num_latent\n",
    "        # graph info\n",
    "        node_base = torch.tensor(list(body_index.values()),dtype=torch.long).squeeze()\n",
    "        node_hip = torch.stack([torch.tensor(list(hip_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_thigh = torch.stack([torch.tensor(list(thigh_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_calf = torch.stack([torch.tensor(list(calf_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        activation_fn = get_activation(activation)\n",
    "        self.node_base = nn.Parameter(node_base, requires_grad=False)\n",
    "        self.node_hip = nn.Parameter(node_hip, requires_grad=False)\n",
    "        self.node_thigh = nn.Parameter(node_thigh, requires_grad=False)\n",
    "        self.node_calf = nn.Parameter(node_calf, requires_grad=False) \n",
    "        self.edge = torch.as_tensor(edge_index, dtype=torch.long).contiguous().t()\n",
    "        # Pipeline\n",
    "        # obs-> node, concat with latent -> node latent\n",
    "        # node latent -> node level policy -> node action\n",
    "        base_input_size =  len(list(body_index.values())[0])\n",
    "        hip_input_size = len(list(hip_index.values())[0])\n",
    "        thigh_input_size =len(list(thigh_index.values())[0])\n",
    "        calf_input_size = len(list(calf_index.values())[0])\n",
    "        self.base_net = mlp(base_input_size, num_latent, [128], activation_fn)\n",
    "        self.hip_net = mlp(hip_input_size, num_latent, [128], activation_fn)\n",
    "        self.thigh_net = mlp(thigh_input_size, num_latent, [128], activation_fn)\n",
    "        self.calf_net = mlp(calf_input_size, num_latent, [128], activation_fn)\n",
    "\n",
    "        # graph neural network \n",
    "        self.gn = ResGatedGraphConv(in_channels=2 * num_latent,\n",
    "                                    out_channels=2 * num_latent)\n",
    "        self.act = activation_fn\n",
    "        self.gn2 = ResGatedGraphConv(in_channels=2 * num_latent,\n",
    "                                    out_channels=num_latent)\n",
    "        \n",
    "        # graph policy : (base, hip, thigh, calf) -> leg_control \n",
    "        self.leg_policy = mlp(4*num_latent, 3, [256,128], activation_fn)\n",
    "        self.FL_Leg = nn.Parameter(torch.tensor([0,1,5,9],dtype=torch.long), requires_grad=False)\n",
    "        self.FR_Leg = nn.Parameter(torch.tensor([0,2,6,10],dtype=torch.long), requires_grad=False)\n",
    "        self.RL_Leg = nn.Parameter(torch.tensor([0,3,7,11],dtype=torch.long), requires_grad=False)\n",
    "        self.RR_Leg = nn.Parameter(torch.tensor([0,4,8,12],dtype=torch.long), requires_grad=False)\n",
    "\n",
    "    def _obs2node(self, obs):\n",
    "        # obs.shape = (bz, n_obs)\n",
    "        base = obs[:,self.node_base].unsqueeze(1) # (bz, 1, n_base)\n",
    "        hip = obs[:,self.node_hip]# (bz, 4, 4)\n",
    "        thigh = obs[:,self.node_thigh]\n",
    "        calf = obs[:,self.node_calf]\n",
    "        base = self.base_net(base)\n",
    "        hip = self.hip_net(hip)\n",
    "        thigh = self.thigh_net(thigh)\n",
    "        calf = self.calf_net(calf)\n",
    "        return torch.cat([base,hip,thigh,calf],dim=1) # (bz, n_node,num_latent)\n",
    "    def forward(self, obs, latent):\n",
    "        # obs.shape = (bz, n_obs)\n",
    "        # latent.shape = (bz,n_node, num_latent)\n",
    "        obs_nodes = self._obs2node(obs) # (bz, n_node, num_latent) \n",
    "        nodes_latent = torch.cat([obs_nodes,latent],dim=-1) # (bz, n_node, 2*num_latent)\n",
    "        nodes_latent = self.gn(nodes_latent, self.edge) # (bz, n_node, 2*num_latent)\n",
    "        nodes_latent = self.act(nodes_latent)\n",
    "        nodes_latent = self.gn2(nodes_latent, self.edge) # (bz, n_node, num_latent) \n",
    "        FL_Leg_latent = nodes_latent[:,self.FL_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        FR_Leg_latent = nodes_latent[:,self.FR_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        RL_Leg_latent = nodes_latent[:,self.RL_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        RR_Leg_latent = nodes_latent[:,self.RR_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        FL_Leg_action = self.leg_policy(FL_Leg_latent)\n",
    "        FR_Leg_action = self.leg_policy(FR_Leg_latent)\n",
    "        RL_Leg_action = self.leg_policy(RL_Leg_latent)\n",
    "        RR_Leg_action = self.leg_policy(RR_Leg_latent)\n",
    "        return torch.cat([FL_Leg_action,FR_Leg_action,RL_Leg_action,RR_Leg_action],dim=1) # (bz, 12)\n",
    "\n",
    "class GraphForward(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_obs,\n",
    "                 num_latent,\n",
    "                 num_actions,\n",
    "                 activation = 'elu',\n",
    "                 actor_hidden_dims = [512, 256, 128]):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        obs + action + latent -> next_obs \n",
    "        obs -> node \n",
    "        action -> node\n",
    "        \"\"\"\n",
    "        self.num_latent = num_latent\n",
    "        # graph info\n",
    "        node_base = torch.tensor(list(body_index.values()),dtype=torch.long).squeeze()\n",
    "        node_hip = torch.stack([torch.tensor(list(hip_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_thigh = torch.stack([torch.tensor(list(thigh_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        node_calf = torch.stack([torch.tensor(list(calf_index.values()),dtype=torch.long)],dim=0).squeeze()\n",
    "        \n",
    "        node_hip_action = torch.tensor([0, 3, 6, 9],dtype=torch.long)\n",
    "        node_thigh_action = torch.tensor([1, 4, 7, 10],dtype=torch.long)\n",
    "        node_calf_action = torch.tensor([2, 5, 8, 11],dtype=torch.long)\n",
    "        self.node_hip_action = nn.Parameter(node_hip_action, requires_grad=False)\n",
    "        self.node_thigh_action = nn.Parameter(node_thigh_action, requires_grad=False)\n",
    "        self.node_calf_action = nn.Parameter(node_calf_action, requires_grad=False)\n",
    "\n",
    "        activation_fn = get_activation(activation)\n",
    "        self.node_base = nn.Parameter(node_base, requires_grad=False)\n",
    "        self.node_hip = nn.Parameter(node_hip, requires_grad=False)\n",
    "        self.node_thigh = nn.Parameter(node_thigh, requires_grad=False)\n",
    "        self.node_calf = nn.Parameter(node_calf, requires_grad=False) \n",
    "        self.edge = nn.Parameter(torch.as_tensor(edge_index, dtype=torch.long).contiguous().t(),requires_grad=False)\n",
    "        # pipeline \n",
    "        base_input_size =  len(list(body_index.values())[0])\n",
    "        hip_input_size = len(list(hip_index.values())[0]) + 1\n",
    "        thigh_input_size =len(list(thigh_index.values())[0]) + 1 \n",
    "        calf_input_size = len(list(calf_index.values())[0]) + 1 \n",
    "        self.base_net = mlp(base_input_size, num_latent, [128], activation_fn)\n",
    "        self.hip_net = mlp(hip_input_size, num_latent, [128], activation_fn)\n",
    "        self.thigh_net = mlp(thigh_input_size, num_latent, [128], activation_fn)\n",
    "        self.calf_net = mlp(calf_input_size, num_latent, [128], activation_fn)\n",
    "        # graph neural network \n",
    "        self.gn = ResGatedGraphConv(in_channels=2 * num_latent,\n",
    "                                    out_channels=2 * num_latent)\n",
    "        self.act = activation_fn\n",
    "        self.gn2 = ResGatedGraphConv(in_channels=2 * num_latent,\n",
    "                                    out_channels=num_latent)\n",
    "        # decoder \n",
    "        ## base_vel, base_ang, project_gravity, cmd\n",
    "        ## dof_pos,vel,actions, contact\n",
    "        self.base_decoder = mlp(num_latent, 3 + 3 + 3 + 3, [128], activation_fn)\n",
    "        self.leg_decoder = mlp(num_latent * 4 , 3 + 3 + 3 + 1, [128], activation_fn)\n",
    "        self.FL_Leg = nn.Parameter(torch.tensor([0,1,5,9],dtype=torch.long), requires_grad=False)\n",
    "        self.FR_Leg = nn.Parameter(torch.tensor([0,2,6,10],dtype=torch.long), requires_grad=False)\n",
    "        self.RL_Leg = nn.Parameter(torch.tensor([0,3,7,11],dtype=torch.long), requires_grad=False)\n",
    "        self.RR_Leg = nn.Parameter(torch.tensor([0,4,8,12],dtype=torch.long), requires_grad=False)\n",
    "\n",
    "\n",
    "    def _obsaction2node(self,obs,action):\n",
    "        base = obs[:,self.node_base].unsqueeze(1) # (bz, 1, n_base)\n",
    "        hip = obs[:,self.node_hip]# (bz, 4, 4)\n",
    "        thigh = obs[:,self.node_thigh]\n",
    "        calf = obs[:,self.node_calf]\n",
    "        hip_action = action[:,self.node_hip_action].unsqueeze(-1)\n",
    "        thigh_action = action[:,self.node_thigh_action].unsqueeze(-1)\n",
    "        calf_action = action[:,self.node_calf_action].unsqueeze(-1)\n",
    "        base = self.base_net(base)\n",
    "        hip = self.hip_net(torch.cat([hip,hip_action],dim=-1))\n",
    "        thigh = self.hip_net(torch.cat([thigh,thigh_action],dim=-1))\n",
    "        calf = self.calf_net(torch.cat([calf,calf_action],dim=-1))\n",
    "        node = torch.cat([base,hip,thigh,calf],dim=1)\n",
    "        return node # shape (bz, 13, 4)\n",
    "\n",
    "    def forward(self,obs,action,latent):\n",
    "        obsaction_node = self._obsaction2node(obs,action) \n",
    "        nodes_latent = torch.cat([obsaction_node,latent],dim=-1) # (bz, n_node, 2*num_latent)\n",
    "        nodes_latent = self.gn(nodes_latent, self.edge) # (bz, n_node, 2*num_latent)\n",
    "        nodes_latent = self.act(nodes_latent)\n",
    "        nodes_latent = self.gn2(nodes_latent, self.edge) # (bz, n_node, num_latent) \n",
    "\n",
    "        Base_latent = nodes_latent[:,0:1,:].reshape(-1,self.num_latent)\n",
    "        FL_Leg_latent = nodes_latent[:,self.FL_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        FR_Leg_latent = nodes_latent[:,self.FR_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        RL_Leg_latent = nodes_latent[:,self.RL_Leg,:].reshape(-1,4*self.num_latent)\n",
    "        RR_Leg_latent = nodes_latent[:,self.RR_Leg,:].reshape(-1,4*self.num_latent)\n",
    "\n",
    "        base_decoded = self.base_decoder(Base_latent) # (bz,12)\n",
    "        FL_Leg_decoded = self.leg_decoder(FL_Leg_latent) # (bz, 4) \n",
    "        FR_Leg_decoded = self.leg_decoder(FR_Leg_latent)\n",
    "        RL_Leg_decoded = self.leg_decoder(RL_Leg_latent)\n",
    "        RR_Leg_decoded = self.leg_decoder(RR_Leg_latent)\n",
    "        decoded_pos = torch.cat([FL_Leg_decoded[:,0:3],FR_Leg_decoded[:,0:3],RL_Leg_decoded[:,0:3],RR_Leg_decoded[:,0:3]],dim=-1) # (bz,12)\n",
    "        decoded_vel = torch.cat([FL_Leg_decoded[:,3:6],FR_Leg_decoded[:,3:6],RL_Leg_decoded[:,3:6],RR_Leg_decoded[:,3:6]],dim=-1)\n",
    "        decoded_act = torch.cat([FL_Leg_decoded[:,6:9],FR_Leg_decoded[:,6:9],RL_Leg_decoded[:,6:9],RR_Leg_decoded[:,6:9]],dim=-1)\n",
    "        decoded_contact = torch.cat([FL_Leg_decoded[:,9:10],FR_Leg_decoded[:,9:10],RL_Leg_decoded[:,9:10],RR_Leg_decoded[:,9:10]],dim=-1)\n",
    "        decoded = torch.cat((base_decoded,decoded_pos,decoded_vel,decoded_act,decoded_contact),dim=-1)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_history = torch.randn(2,10,52)\n",
    "obs = torch.randn(2,52)\n",
    "\n",
    "obs_history_dim = 10 * 52 \n",
    "\n",
    "vq = VectorQuantize(\n",
    "    dim = 256,\n",
    "    codebook_dim = 32,                  # a number of papers have shown smaller codebook dimension to be acceptable\n",
    "    heads = 8,                          # number of heads to vector quantize, codebook shared across all heads\n",
    "    separate_codebook_per_head = True,  # whether to have a separate codebook per head. False would mean 1 shared codebook\n",
    "    codebook_size = 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(obs_history_dim, 256),\n",
    "    vq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = net(obs_history.reshape(2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
